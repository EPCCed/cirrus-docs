
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../python/">
      
      
        <link rel="next" href="../solidstate/">
      
      
      <link rel="icon" href="../../favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.7">
    
    
      
        <title>Using the Cirrus GPU Nodes - Cirrus User Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.8608ea7d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/cirrus.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-3T9RVR5FTP"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-3T9RVR5FTP",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-3T9RVR5FTP",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="teal">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#using-the-cirrus-gpu-nodes" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Cirrus User Documentation" class="md-header__button md-logo" aria-label="Cirrus User Documentation" data-md-component="logo">
      
  <img src="../../images/cirrus_logo_white-Transparent-Background.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Cirrus User Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Using the Cirrus GPU Nodes
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EPCCed/cirrus-docs" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    EPCCed/cirrus-docs
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Cirrus User Documentation" class="md-nav__button md-logo" aria-label="Cirrus User Documentation" data-md-component="logo">
      
  <img src="../../images/cirrus_logo_white-Transparent-Background.png" alt="logo">

    </a>
    Cirrus User Documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EPCCed/cirrus-docs" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    EPCCed/cirrus-docs
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../e1000-migration" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cirrus migration to E1000 system
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    User Guide
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            User Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../connecting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Connecting to Cirrus
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Management and Transfer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../resource_management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    File and Resource Management
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../development/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Application Development Environment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../batch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Running Jobs on Cirrus
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../singularity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Singularity Containers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../python/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using Python
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Using the Cirrus GPU Nodes
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Using the Cirrus GPU Nodes
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#hardware-details" class="md-nav__link">
    <span class="md-ellipsis">
      Hardware details
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#compiling-software-for-the-gpu-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      Compiling software for the GPU nodes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Compiling software for the GPU nodes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#nvidia-hpc-sdk" class="md-nav__link">
    <span class="md-ellipsis">
      NVIDIA HPC SDK
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#using-cuda-with-intel-compilers" class="md-nav__link">
    <span class="md-ellipsis">
      Using CUDA with Intel compilers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compiling-openacc-code" class="md-nav__link">
    <span class="md-ellipsis">
      Compiling OpenACC code
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-fortran" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA Fortran
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#openmp-for-gpus" class="md-nav__link">
    <span class="md-ellipsis">
      OpenMP for GPUs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sycl" class="md-nav__link">
    <span class="md-ellipsis">
      SYCL
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#submitting-jobs-to-the-gpu-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      Submitting jobs to the GPU nodes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Submitting jobs to the GPU nodes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#partitions" class="md-nav__link">
    <span class="md-ellipsis">
      Partitions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quality-of-service-qos" class="md-nav__link">
    <span class="md-ellipsis">
      Quality of Service (QoS)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples" class="md-nav__link">
    <span class="md-ellipsis">
      Examples
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Examples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#job-submission-script-using-one-gpu-on-a-single-node" class="md-nav__link">
    <span class="md-ellipsis">
      Job submission script using one GPU on a single node
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#job-submission-script-using-multiple-gpus-on-a-single-node" class="md-nav__link">
    <span class="md-ellipsis">
      Job submission script using multiple GPUs on a single node
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#job-submission-script-using-multiple-gpus-on-multiple-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      Job submission script using multiple GPUs on multiple nodes
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#debugging-gpu-applications" class="md-nav__link">
    <span class="md-ellipsis">
      Debugging GPU applications
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#profiling-gpu-applications" class="md-nav__link">
    <span class="md-ellipsis">
      Profiling GPU applications
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Profiling GPU applications">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#using-nsight-systems" class="md-nav__link">
    <span class="md-ellipsis">
      Using Nsight Systems
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-nsight-compute" class="md-nav__link">
    <span class="md-ellipsis">
      Using Nsight Compute
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#monitoring-the-gpu-power-usage" class="md-nav__link">
    <span class="md-ellipsis">
      Monitoring the GPU Power Usage
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#compiling-and-using-gpu-aware-mpi" class="md-nav__link">
    <span class="md-ellipsis">
      Compiling and using GPU-aware MPI
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Compiling and using GPU-aware MPI">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compiling-cc" class="md-nav__link">
    <span class="md-ellipsis">
      Compiling C/C++
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compiling-fortran" class="md-nav__link">
    <span class="md-ellipsis">
      Compiling Fortran
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-time" class="md-nav__link">
    <span class="md-ellipsis">
      Run time
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../solidstate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Solid state storage
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Software Applications
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Software Applications
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/castep/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Castep
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/cp2k/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CP2K
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/elements/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ELEMENTS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/flacs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FLACS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/gaussian/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gaussian
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/gromacs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GROMACS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/helyx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HELYX&reg;
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/lammps/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LAMMPS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/MATLAB/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MATLAB
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/namd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NAMD
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/openfoam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenFOAM
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/orca/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ORCA
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/qe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quantum Espresso (QE)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/starccm%2B/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    STAR-CCM+
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-packages/vasp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VASP
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Software Libraries
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Software Libraries
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-libraries/intel_mkl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Intel MKL: BLAS, LAPACK, ScaLAPACK
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-libraries/hdf5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HDF5
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Software Tools
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Software Tools
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-tools/forge/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linaro Forge
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-tools/scalasca/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling using Scalasca
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../software-tools/intel-vtune/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Intel VTune
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../reading/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    References and further reading
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#hardware-details" class="md-nav__link">
    <span class="md-ellipsis">
      Hardware details
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#compiling-software-for-the-gpu-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      Compiling software for the GPU nodes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Compiling software for the GPU nodes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#nvidia-hpc-sdk" class="md-nav__link">
    <span class="md-ellipsis">
      NVIDIA HPC SDK
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#using-cuda-with-intel-compilers" class="md-nav__link">
    <span class="md-ellipsis">
      Using CUDA with Intel compilers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compiling-openacc-code" class="md-nav__link">
    <span class="md-ellipsis">
      Compiling OpenACC code
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-fortran" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA Fortran
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#openmp-for-gpus" class="md-nav__link">
    <span class="md-ellipsis">
      OpenMP for GPUs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sycl" class="md-nav__link">
    <span class="md-ellipsis">
      SYCL
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#submitting-jobs-to-the-gpu-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      Submitting jobs to the GPU nodes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Submitting jobs to the GPU nodes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#partitions" class="md-nav__link">
    <span class="md-ellipsis">
      Partitions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quality-of-service-qos" class="md-nav__link">
    <span class="md-ellipsis">
      Quality of Service (QoS)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples" class="md-nav__link">
    <span class="md-ellipsis">
      Examples
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Examples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#job-submission-script-using-one-gpu-on-a-single-node" class="md-nav__link">
    <span class="md-ellipsis">
      Job submission script using one GPU on a single node
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#job-submission-script-using-multiple-gpus-on-a-single-node" class="md-nav__link">
    <span class="md-ellipsis">
      Job submission script using multiple GPUs on a single node
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#job-submission-script-using-multiple-gpus-on-multiple-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      Job submission script using multiple GPUs on multiple nodes
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#debugging-gpu-applications" class="md-nav__link">
    <span class="md-ellipsis">
      Debugging GPU applications
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#profiling-gpu-applications" class="md-nav__link">
    <span class="md-ellipsis">
      Profiling GPU applications
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Profiling GPU applications">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#using-nsight-systems" class="md-nav__link">
    <span class="md-ellipsis">
      Using Nsight Systems
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-nsight-compute" class="md-nav__link">
    <span class="md-ellipsis">
      Using Nsight Compute
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#monitoring-the-gpu-power-usage" class="md-nav__link">
    <span class="md-ellipsis">
      Monitoring the GPU Power Usage
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#compiling-and-using-gpu-aware-mpi" class="md-nav__link">
    <span class="md-ellipsis">
      Compiling and using GPU-aware MPI
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Compiling and using GPU-aware MPI">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compiling-cc" class="md-nav__link">
    <span class="md-ellipsis">
      Compiling C/C++
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compiling-fortran" class="md-nav__link">
    <span class="md-ellipsis">
      Compiling Fortran
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-time" class="md-nav__link">
    <span class="md-ellipsis">
      Run time
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="using-the-cirrus-gpu-nodes">Using the Cirrus GPU Nodes</h1>
<p>Cirrus has 38 GPU compute nodes each equipped with 4 NVIDIA V100 (Volta)
GPU cards. This section of the user guide gives some details of the
hardware; it also covers how to compile and run standard GPU
applications.</p>
<p>The GPU cards on Cirrus do not support graphics rendering tasks; they
are set to <span class="title-ref">compute cluster</span> mode and so
only support computational tasks.</p>
<h2 id="hardware-details">Hardware details</h2>
<p>All of the Cirrus GPU nodes contain four Tesla V100-SXM2-16GB (Volta)
cards. Each card has 16 GB of high-bandwidth memory, <code>HBM</code>, often
referred to as device memory. Maximum device memory bandwidth is in the
region of 900 GB per second. Each card has 5,120 CUDA cores and 640
Tensor cores.</p>
<p>There is one GPU Slurm partition installed on Cirrus called simply
<code>gpu</code>. The 36 nodes in this partition have the Intel Cascade Lake
architecture. Users concerned with host performance should add the
specific compilation options appropriate for the processor.</p>
<p>The Cascade Lake nodes have two 20-core sockets (2.5 GHz) and a total of
384 GB host memory (192 GB per socket). Each core supports two threads
in hardware.</p>
<p>For further details of the V100 architecture see,
<a href="https://www.nvidia.com/en-gb/data-center/tesla-v100/">https://www.nvidia.com/en-gb/data-center/tesla-v100/</a> .</p>
<h2 id="compiling-software-for-the-gpu-nodes">Compiling software for the GPU nodes</h2>
<h3 id="nvidia-hpc-sdk">NVIDIA HPC SDK</h3>
<p>NVIDIA now make regular releases of a unified HPC SDK which provides the
relevant compilers and libraries needed to build and run GPU programs.
Versions of the SDK are available via the module system.</p>
<pre><code>$ module avail nvidia/nvhpc
</code></pre>
<p>NVIDIA encourage the use of the latest available version, unless there
are particular reasons to use earlier versions. The default version is
therefore the latest module version present on the system.</p>
<p>Each release of the NVIDIA HPC SDK may include several different
versions of the CUDA toolchain. Only one of these CUDA toolchains
can be active at any one time and for <code>nvhpc/24.5</code> this is CUDA 12.4.</p>
<p>Here is a list of available HPC SDK versions, and the corresponding
version of CUDA:</p>
<table>
<thead>
<tr>
<th>Module</th>
<th>Supported CUDA Version</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>nvidia/nvhpc/24.5</code></td>
<td>CUDA 12.4</td>
</tr>
<tr>
<td><code>nvidia/nvhpc/22.11</code></td>
<td>CUDA 11.8</td>
</tr>
<tr>
<td><code>nvidia/nvhpc/22.2</code></td>
<td>CUDA 11.6</td>
</tr>
</tbody>
</table>
<p>To load the latest NVIDIA HPC SDK use</p>
<pre><code>$ module load gcc
$ module load nvidia/nvhpc
</code></pre>
<p>The following sections provide some details of compilation for different
programming models.</p>
<h3 id="cuda">CUDA</h3>
<p><a href="https://developer.nvidia.com/cuda-zone">CUDA</a> is a parallel computing
platform and programming model developed by NVIDIA for general computing
on graphical processing units (GPUs).</p>
<p>Programs, typically written in C or C++, are compiled with <code>nvcc</code>. As
well as <code>nvcc</code>, a host compiler is required. This is usually <code>gcc</code>
meaning the <code>gcc</code> module should also be loaded, as above.</p>
<p>Compile your source code in the usual way.</p>
<pre><code>nvcc -arch=sm_70 -o cuda_test.x cuda_test.cu
</code></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code>-arch=sm_70</code> compile option ensures that the binary produced is
compatible with the NVIDIA Volta architecture.</p>
</div>
<h4 id="using-cuda-with-intel-compilers">Using CUDA with Intel compilers</h4>
<p>You can load either the Intel 19 or Intel 20 compilers to use with
<code>nvcc</code>.</p>
<pre><code>module unload gcc
module load intel-20.4/compilers
</code></pre>
<p>You can now use <code>nvcc -ccbin icpc</code> to compile your source code with the
Intel C++ compiler <code>icpc</code>.</p>
<pre><code>nvcc -arch=sm_70 -ccbin icpc -o cuda_test.x cuda_test.cu
</code></pre>
<h3 id="compiling-openacc-code">Compiling OpenACC code</h3>
<p>OpenACC is a directive-based approach to introducing parallelism into
either C/C++ or Fortran codes. A code with OpenACC directives may be
compiled like so.</p>
<pre><code>$ module load gcc
$ module load nvidia/nvhpc
$ nvc program.c

$ nvc++ program.cpp
</code></pre>
<p>Note that <code>nvc</code> and <code>nvc++</code> are distinct from the NVIDIA CUDA compiler
<code>nvcc</code>. They provide a way to compile standard C or C++ programs without
explicit CUDA content. See <code>man nvc</code> or <code>man nvc++</code> for further details.</p>
<h3 id="cuda-fortran">CUDA Fortran</h3>
<p>CUDA Fortran provides extensions to standard Fortran which allow GPU
functionality. CUDA Fortran files (with file extension <code>.cuf</code>) may be
compiled with the NVIDIA Fortran compiler.</p>
<pre><code>$ module load gcc
$ module load nvidia/nvhpc
$ nvfortran program.cuf
</code></pre>
<p>See <code>man nvfortran</code> for further details.</p>
<h3 id="openmp-for-gpus">OpenMP for GPUs</h3>
<p>The OpenMP API supports multi-platform shared-memory parallel
programming in C/C++ and Fortran and can offload computation from the
host (i.e. CPU) to one or more target devices (such as the GPUs on
Cirrus). OpenMP code can be compiled with the NVIDIA compilers in a
similar manner to OpenACC. To enable this functionality, you must add
<code>-mp=gpu</code> to your compile command.</p>
<pre><code>$ module load gcc
$ module load nvidia/nvhpc
$ nvc++ -mp=gpu program.cpp
</code></pre>
<p>You can specify exactly which GPU to target with the <code>-gpu</code> flag. For
example, the Volta cards on Cirrus use the flag <code>-gpu=cc70</code>.</p>
<p>During development it can be useful to have the compiler report
information about how it is processing OpenMP pragmas. This can be
enabled by the use of <code>-Minfo=mp</code>, see below.</p>
<pre><code>nvc -mp=gpu -Minfo=mp testprogram.c
main:
24, #omp target teams distribute parallel for thread_limit(128)
24, Generating Tesla and Multicore code
Generating "nvkernel_main_F1L88_2" GPU kernel
26, Loop parallelized across teams and threads(128), schedule(static)
</code></pre>
<h3 id="sycl">SYCL</h3>
<p>This section shows how to compile SYCL codes using the Intel compiler. First,
load the following modules:</p>
<pre><code>module load gcc/10.2.0 nvidia/nvhpc/22.11
module load oneapi
module load compiler
</code></pre>
<p>Once the above modules are loaded, you can compile the code using the following:</p>
<pre><code>icpx -fsycl code.cpp
</code></pre>
<p>For testing, you can use material from the <a href="https://github.com/codeplaysoftware/syclacademy">SYCL Academy repository</a>.</p>
<h2 id="submitting-jobs-to-the-gpu-nodes">Submitting jobs to the GPU nodes</h2>
<p>To run a GPU job, a SLURM submission must specify a GPU partition and a
quality of service (QoS) as well as the number of GPUs required. You
specify the number of GPU cards you want using the <code>--gres=gpu:N</code>
option, where <code>N</code> is typically 1, 2 or 4.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As there are 4 GPUs per node, each GPU is associated with 1/4 of the
resources of the node, i.e., 10/40 physical cores and roughly 91/384 GB
in host memory.</p>
</div>
<p>Allocations of host resources are made pro-rata. For example, if 2 GPUs
are requested, <code>sbatch</code> will allocate 20 cores and around 190 GB of host
memory (in addition to 2 GPUs). Any attempt to use more than the
allocated resources will result in an error.</p>
<p>This automatic allocation by SLURM for GPU jobs means that the
submission script should not specify options such as <code>--ntasks</code> and
<code>--cpus-per-task</code>. Such a job submission will be rejected. See below for
some examples of how to use host resources and how to launch MPI
applications.</p>
<p>If you specify the <code>--exclusive</code> option, you will automatically be
allocated all host cores and all memory from the node irrespective of
how many GPUs you request. This may be needed if the application has a
large host memory requirement.</p>
<p>If more than one node is required, exclusive mode <code>--exclusive</code> and
<code>--gres=gpu:4</code> options must be included in your submission script. It
is, for example, not possible to request 6 GPUs other than via exclusive
use of two nodes.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>In order to run jobs on the GPU nodes your budget must have positive GPU
hours <em>and</em> positive CPU core hours associated with it. However, only
your GPU hours will be consumed when running these jobs.</p>
</div>
<h3 id="partitions">Partitions</h3>
<p>Your job script must specify a partition. The following table has a list
of relevant GPU partition(s) on Cirrus.</p>
<table>
<thead>
<tr>
<th>Partition</th>
<th>Description</th>
<th>Maximum Job Size (Nodes)</th>
</tr>
</thead>
<tbody>
<tr>
<td>gpu</td>
<td>GPU nodes with Cascade Lake processors</td>
<td>36</td>
</tr>
</tbody>
</table>
<h3 id="quality-of-service-qos">Quality of Service (QoS)</h3>
<p>Your job script must specify a QoS relevant for the GPU nodes. Available
QoS specifications are as follows.</p>
<table>
<thead>
<tr>
<th>QoS Name</th>
<th>Jobs Running Per User</th>
<th>Jobs Queued Per User</th>
<th>Max Walltime</th>
<th>Max Size</th>
<th>Partition</th>
</tr>
</thead>
<tbody>
<tr>
<td>gpu</td>
<td>No limit</td>
<td>128 jobs</td>
<td>4 days</td>
<td>64 GPUs</td>
<td>gpu</td>
</tr>
<tr>
<td>long</td>
<td>5 jobs</td>
<td>20 jobs</td>
<td>14 days</td>
<td>8 GPUs</td>
<td>gpu</td>
</tr>
<tr>
<td>short</td>
<td>1 job</td>
<td>2 jobs</td>
<td>20 minutes</td>
<td>4 GPUs</td>
<td>gpu</td>
</tr>
<tr>
<td>lowpriority</td>
<td>No limit</td>
<td>100 jobs</td>
<td>2 days</td>
<td>16 GPUs</td>
<td>gpu</td>
</tr>
<tr>
<td>largescale</td>
<td>1 job</td>
<td>4 jobs</td>
<td>24 hours</td>
<td>144 GPUs</td>
<td>gpu</td>
</tr>
</tbody>
</table>
<h2 id="examples">Examples</h2>
<h3 id="job-submission-script-using-one-gpu-on-a-single-node">Job submission script using one GPU on a single node</h3>
<p>A job script that requires 1 GPU accelerator and 10 CPU cores for 20
minutes would look like the following.</p>
<pre><code>#!/bin/bash
#
#SBATCH --partition=gpu
#SBATCH --qos=gpu
#SBATCH --gres=gpu:1
#SBATCH --time=00:20:00

# Replace [budget code] below with your project code (e.g. t01)
#SBATCH --account=[budget code]

# Load the required modules
module load nvidia/nvhpc

srun ./cuda_test.x
</code></pre>
<p>This will execute one host process with access to one GPU. If we wish to
make use of the 10 host cores in this allocation, we could use host
threads via OpenMP.</p>
<pre><code>export OMP_NUM_THREADS=10
export OMP_PLACES=cores

srun --ntasks=1 --cpus-per-task=10 --hint=nomultithread ./cuda_test.x
</code></pre>
<p>The launch configuration is specified directly to <code>srun</code> because, for
the GPU partitions, it is not possible to do this via <code>sbatch</code>.</p>
<h3 id="job-submission-script-using-multiple-gpus-on-a-single-node">Job submission script using multiple GPUs on a single node</h3>
<p>A job script that requires 4 GPU accelerators and 40 CPU cores for 20
minutes would appear as follows.</p>
<pre><code>#!/bin/bash
#
#SBATCH --partition=gpu
#SBATCH --qos=gpu
#SBATCH --gres=gpu:4
#SBATCH --time=00:20:00

# Replace [budget code] below with your project code (e.g. t01)
#SBATCH --account=[budget code]

# Load the required modules
module load nvidia/nvhpc

srun ./cuda_test.x
</code></pre>
<p>A typical MPI application might assign one device per MPI process, in
which case we would want 4 MPI tasks in this example. This would again
be specified directly to <code>srun</code>.</p>
<pre><code>srun --ntasks=4 ./mpi_cuda_test.x
</code></pre>
<h3 id="job-submission-script-using-multiple-gpus-on-multiple-nodes">Job submission script using multiple GPUs on multiple nodes</h3>
<p>See below for a job script that requires 8 GPU accelerators for 20
minutes.</p>
<pre><code>#!/bin/bash
#
#SBATCH --partition=gpu
#SBATCH --qos=gpu
#SBATCH --gres=gpu:4
#SBATCH --nodes=2
#SBATCH --exclusive
#SBATCH --time=00:20:00

# Replace [budget code] below with your project code (e.g. t01)
#SBATCH --account=[budget code]

# Load the required modules
module load nvidia/nvhpc

srun ./cuda_test.x
</code></pre>
<p>An MPI application with four MPI tasks per node would be launched as
follows.</p>
<pre><code>srun --ntasks=8 --tasks-per-node=4 ./mpi_cuda_test.x
</code></pre>
<p>Again, these options are specified directly to <code>srun</code> rather than being
declared as <code>sbatch</code> directives.</p>
<p>Attempts to oversubscribe an allocation (10 cores per GPU) will fail,
and generate an error message.</p>
<pre><code>srun: error: Unable to create step for job 234123: More processors requested
than permitted
</code></pre>
<h2 id="debugging-gpu-applications">Debugging GPU applications</h2>
<p>Applications may be debugged using <code>cuda-gdb</code>. This is an extension of
<code>gdb</code> which can be used with CUDA. We assume the reader is familiar with
<code>gdb</code>.</p>
<p>First, compile the application with the <code>-g -G</code> flags in order to
generate debugging information for both host and device code. Then,
obtain an interactive session like so.</p>
<pre><code>$ srun --nodes=1 --partition=gpu --qos=short --gres=gpu:1 \
       --time=0:20:0 --account=[budget code] --pty /bin/bash
</code></pre>
<p>Next, load the NVIDIA HPC SDK module and start <code>cuda-gdb</code> for your
application.</p>
<pre><code>$ module load nvidia/nvhpc
$ cuda-gdb ./my-application.x
NVIDIA (R) CUDA Debugger
...
(cuda-gdb)
</code></pre>
<p>Debugging then proceeds as usual. One can use the help facility within
<code>cuda-gdb</code> to find details on the various debugging commands. Type
<code>quit</code> to end your debug session followed by <code>exit</code> to close the
interactive session.</p>
<p>Note, it may be necessary to set the temporary directory to somewhere in
the user space (e.g., <code>export TMPDIR=$(pwd)/tmp</code>) to prevent unexpected
internal CUDA driver errors.</p>
<p>For further information on CUDA-GDB, see
<a href="https://docs.nvidia.com/cuda/cuda-gdb/index.html">https://docs.nvidia.com/cuda/cuda-gdb/index.html</a>.</p>
<h2 id="profiling-gpu-applications">Profiling GPU applications</h2>
<p>NVIDIA provide two useful tools for profiling performance of
applications: Nsight Systems and Nsight Compute; the former provides an
overview of application performance, while the latter provides detailed
information specifically on GPU kernels.</p>
<h3 id="using-nsight-systems">Using Nsight Systems</h3>
<p>Nsight Systems provides an overview of application performance and
should therefore be the starting point for investigation. To run an
application, compile as normal (including the <code>-g</code> flag) and then submit
a batch job.</p>
<pre><code>#!/bin/bash

#SBATCH --time=00:10:00
#SBATCH --nodes=1
#SBATCH --exclusive
#SBATCH --partition=gpu
#SBATCH --qos=short
#SBATCH --gres=gpu:1

# Replace [budget code] below with your project code (e.g. t01)
#SBATCH --account=[budget code]

module load nvidia/nvhpc

srun -n 1 nsys profile -o prof1 ./my_application.x
</code></pre>
<p>The run should then produce an additional output file called, in this
case, <code>prof1.qdrep</code>. The recommended way to view the contents of this
file is to download the NVIDIA Nsight package to your own machine (you
do not need the entire HPC SDK). Then copy the <code>.qdrep</code> file produced on
Cirrus so that if can be viewed locally.</p>
<p>Note, a profiling run should probably be of a short duration so that the
profile information (contained in the <code>.qdrep</code> file) does not become
prohibitively large.</p>
<p>Details of the download of Nsight Systems and a user guide can be found
via the links below.</p>
<p><a href="https://developer.nvidia.com/nsight-systems">https://developer.nvidia.com/nsight-systems</a></p>
<p><a href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html">https://docs.nvidia.com/nsight-systems/UserGuide/index.html</a></p>
<p>If your code was compiled with the tools provided by <code>nvidia/nvhpc/22.2</code>
you should download and install Nsight Systems v2023.4.1.97.</p>
<h3 id="using-nsight-compute">Using Nsight Compute</h3>
<p>Nsight Compute may be used in a similar way as Nsight Systems. A job may
be submitted like so.</p>
<pre><code>#!/bin/bash

#SBATCH --time=00:10:00
#SBATCH --nodes=1
#SBATCH --exclusive
#SBATCH --partition=gpu
#SBATCH --qos=short
#SBATCH --gres=gpu:1

# Replace [budget code] below with your project code (e.g. t01)
#SBATCH --account=[budget code]

module load nvidia/nvhpc

srun -n 1 ncu --section SpeedOfLight_RooflineChart \
                           -o prof2 -f ./my_application.x
</code></pre>
<p>In this case, a file called <code>prof2.ncu-rep</code> should be produced. Again,
the recommended way to view this file is to download the Nsight Compute
package to your own machine, along with the <code>.ncu-rep</code> file from Cirrus.
The <code>--section</code> option determines which statistics are recorded
(typically not all hardware counters can be accessed at the same time).
A common starting point is <code>--section MemoryWorkloadAnalysis</code>.</p>
<p>Consult the NVIDIA documentation for further details.</p>
<p><a href="https://developer.nvidia.com/nsight-compute">https://developer.nvidia.com/nsight-compute</a></p>
<p><a href="https://docs.nvidia.com/nsight-compute/2024.1/index.html">https://docs.nvidia.com/nsight-compute/2024.1/index.html</a></p>
<h2 id="monitoring-the-gpu-power-usage">Monitoring the GPU Power Usage</h2>
<p>NVIDIA also provides a useful command line utility for the management and monitoring of NVIDIA GPUs: the NVIDIA System Management Interface <code>nvidia-smi</code>.</p>
<p>The <code>nvidia-smi</code> command queries the available GPUs and reports current information, including but not limited to: driver versions, CUDA version, name, temperature, current power usage and maximum power capability. In this example output, there is one available GPU and it is idle:</p>
<div class="highlight"><pre><span></span><code>  +-----------------------------------------------------------------------------+
  | NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |
  |-------------------------------+----------------------+----------------------+
  | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
  | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
  |                               |                      |               MIG M. |
  |===============================+======================+======================|
  |   0  Tesla V100-SXM2...  Off  | 00000000:1C:00.0 Off |                  Off |
  | N/A   38C    P0    57W / 300W |      0MiB / 16384MiB |      1%      Default |
  |                               |                      |                  N/A |
  +-------------------------------+----------------------+----------------------+

  +-----------------------------------------------------------------------------+
  | Processes:                                                                  |
  |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
  |        ID   ID                                                   Usage      |
  |=============================================================================|
  |  No running processes found                                                 |
  +-----------------------------------------------------------------------------+
</code></pre></div>
<p>To monitor the power usage throughout the duration of a job, the output of nvidia-smi will report data at every specified interval with the --loop=SEC option with the tool sleeping in-between queries. The following command will print the output of nvidia-smi every 10 seconds in the specified output file.</p>
<pre><code>nvidia-smi --loop=10 --filename=out-nvidia-smi.txt &amp;
</code></pre>
<p>Example submission script:</p>
<pre><code>#!/bin/bash --login

# Slurm job options (name, compute nodes, job time)
#SBATCH --job-name=lammps_Example
#SBATCH --time=00:20:00
#SBATCH --nodes=1
#SBATCH --gres=gpu:4

# Replace [budget code] below with your project code (e.g. t01)
#SBATCH --account=[budget code]
#SBATCH --partition=gpu
#SBATCH --qos=gpu

# Load the required modules
module load nvidia/nvhpc

# Save the output of NVIDIA-SMI every 10 seconds
nvidia-smi --loop=10 --filename=out-nvidia-smi.txt &amp;
srun ./cuda_test.x
</code></pre>
<p>This submission script uses 4 GPU accelerators for 20 minutes, printing the output of nvidia-smi every 10 seconds to the nvidia-smi.txt output file. The &amp; means the shell executes the command in the background.</p>
<p>Consult the NVIDIA documentation for further details.</p>
<p><a href="https://developer.nvidia.com/nvidia-system-management-interface">https://developer.nvidia.com/nvidia-system-management-interface</a></p>
<h2 id="compiling-and-using-gpu-aware-mpi">Compiling and using GPU-aware MPI</h2>
<p>For applications using message passing via MPI, considerable
improvements in performance may be available by allowing device memory
references in MPI calls. This allows replacement of relevant host device
transfers by direct communication within a node via NVLink. Between
nodes, MPI communication will remain limited by network latency and
bandwidth.</p>
<p>Version of OpenMPI with both CUDA-aware MPI support and SLURM support
are available.</p>
<p>The modules you need to load and the command you use to compile depend on whether you are compiling
C/C++ or Fortran.</p>
<h3 id="compiling-cc">Compiling C/C++</h3>
<p>You should load the following modules:</p>
<pre><code>module load openmpi/4.1.6-cuda-12.4
module load nvidia/nvhpc-nompi/24.5
</code></pre>
<p>The location of the MPI include files and libraries must be specified
explicitly, e.g.,</p>
<pre><code>nvcc -I${MPI_HOME}/include  -L${MPI_HOME}/lib -lmpi -o my_program.x my_program.cu
</code></pre>
<p>This will produce an executable in the usual way.</p>
<h3 id="compiling-fortran">Compiling Fortran</h3>
<p>You should load the following modules:</p>
<pre><code>module load openmpi/4.1.6-cuda-12.4-nvfortran
module load nvidia/nvhpc-nompi/24.5
</code></pre>
<p>Use the <code>mpif90</code> compiler wrapper to compile Fortran code for GPU. e.g.</p>
<pre><code>mpif90 -o my_program.x my_program.f90
</code></pre>
<p>This will produce an executable in the usual way.</p>
<h3 id="run-time">Run time</h3>
<p>A batch script to use such an executable might be:</p>
<pre><code>#!/bin/bash

#SBATCH --time=00:20:00

#SBATCH --nodes=1
#SBATCH --partition=gpu
#SBATCH --qos=gpu
#SBATCH --gres=gpu:4

# Load the appropriate modules, e.g.,
module load openmpi/4.1.6-cuda-12.4
module load nvidia/nvhpc-nompi/24.5

export OMP_NUM_THREADS=1

srun --ntasks=4 --cpus-per-task=10 --hint=nomultithread ./my_program
</code></pre>
<p>As before, MPI and placement options should be directly specified to
<code>srun</code> and not via <code>SBATCH</code> directives.</p>
<p>It is possible you may still see warning messages at run time concerning
<code>fork()</code>. These may be safely ignored.</p>









  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/EPCCed" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["tabs"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>